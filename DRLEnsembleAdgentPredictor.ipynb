{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Alpaca Trading Bot\n",
    "## Introduction\n",
    "This notebook demonstrates the process of creating an ensemble trading strategy and testing it on the Dow Jones 30 index. The ensemble is composed of three Deep Reinforcement Learning (DRL) algorithms - Advantage Actor-Critic (A2C), Proximal Policy Optimization (PPO), and Deep Deterministic Policy Gradient (DDPG). The code used in this notebook is based on the [FinRL-Library](https://github.com/AI4Finance-Foundation/FinRL) which is a Python library for financial reinforcement learning developed by AI4Finance-LLC."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required Packages\n",
    "We begin by installing the packages required to run this notebook. These packages are:\n",
    "\n",
    "- `setuptools==64.0.2`: A package for downloading and installing Python packages.\n",
    "- `swig`: A package required by `wrds` package.\n",
    "- `wrds`: A package for downloading data from the Wharton Research Data Services.\n",
    "- `git+https://github.com/AI4Finance-LLC/FinRL-Library.git`: The FinRL-Library package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install setuptools==64.0.2\n",
    "!apt-get install swig\n",
    "!pip3 install wrds\n",
    "!pip3 install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "The first line of the script imports the warnings module, which provides a way to handle warnings that may be encountered during the execution of the script. The second line of the script filters out warnings to avoid clutter in the output.\n",
    "\n",
    "The next lines of the script import the following libraries:\n",
    "\n",
    "- `pandas` (`pd`) and `numpy` (`np`) for data analysis and manipulation.\n",
    "- `matplotlib` for creating visualizations of the data.\n",
    "- `datetime` for handling date and time information.\n",
    "\n",
    "### Importing Required Modules\n",
    "The following modules are then imported:\n",
    "\n",
    "- `DOW_30_TICKER` from `finrl.config_tickers` to specify a list of tickers for the Dow Jones Industrial Average.\n",
    "- `YahooDownloader` from `finrl.meta.preprocessor.yahoodownloader` to download financial data from Yahoo Finance.\n",
    "- `FeatureEngineer` and `data_split` from `finrl.meta.preprocessor.preprocessors` for data pre-processing.\n",
    "- `StockTradingEnv` from `finrl.meta.env_stock_trading.env_stocktrading` to define a custom environment for stock trading.\n",
    "- `DRLAgent` and `DRLEnsembleAgent` from `finrl.agents.stablebaselines3.models` for reinforcement learning agents.\n",
    "- `backtest_stats`, `backtest_plot`, `get_daily_return`, and `get_baseline` from `finrl.plot` for creating plots and calculating performance metrics.\n",
    "- `pprint` for pretty-printing objects.\n",
    "\n",
    "### Setting Configuration Variables\n",
    "The last few lines of the script set configuration variables for data pre-processing, model training, and testing. These include:\n",
    "\n",
    "- `sys.path.append(\"../FinRL-Library\")` to add the FinRL-Library directory to the system path.\n",
    "- `check_and_make_directories` from `finrl.main` to create directories for data storage, model training, and testing results.\n",
    "- `DATA_SAVE_DIR`, `TRAINED_MODEL_DIR`, `TENSORBOARD_LOG_DIR`, and `RESULTS_DIR` for specifying the paths to the data storage, model training, and testing results directories.\n",
    "- `INDICATORS` to specify a list of technical indicators to be used in feature engineering.\n",
    "- `TRAIN_START_DATE`, `TRAIN_END_DATE`, `TEST_START_DATE`, `TEST_END_DATE`, `TRADE_START_DATE`, and `TRADE_END_DATE` to specify the start and end dates for training, testing, and trading periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DOW_30_TICKER` variable contains a list of 30 stock tickers of companies that are part of the Dow Jones Industrial Average.\n",
    "\n",
    "The code defines four date variables for training and testing purposes, namely `TRAIN_START_DATE`, `TRAIN_END_DATE`, `TEST_START_DATE`, and `TEST_END_DATE`.\n",
    "\n",
    "Then, the code creates a DataFrame object `df` using the `YahooDownloader` class from the `finrl` package. The `YahooDownloader` object takes four parameters, namely `start_date`, `end_date`, `ticker_list`, and `fetch_data()`. The `start_date` and `end_date` parameters are set to `TRAIN_START_DATE` and `TEST_END_DATE`, respectively. The `ticker_list` parameter is set to `DOW_30_TICKER`, which is the list of stock tickers imported earlier. The `fetch_data()` method fetches historical stock price data from Yahoo Finance for the specified ticker list and date range.\n",
    "\n",
    "After creating the df `DataFrame`, the code prints the first five rows of the `DataFrame` using the `head()` method, followed by the last five rows using the `tail()` method, and then the shape of the `DataFrame` using the `shape` attribute.\n",
    "\n",
    "Next, the code sorts the `df` `DataFrame` by date and ticker using the `sort_values()` method and prints the first five rows of the sorted DataFrame.\n",
    "\n",
    "The code then prints the number of unique tickers in the `DataFrame` using the `unique()` method applied to the tic column of the `DataFrame`.\n",
    "\n",
    "Finally, the code prints the count of each ticker in the `DataFrame` using the `value_counts()` method applied to the tic column of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DOW_30_TICKER)\n",
    "\n",
    "TRAIN_START_DATE = '2009-04-01'\n",
    "TRAIN_END_DATE = '2021-01-01'\n",
    "TEST_START_DATE = '2021-01-01'\n",
    "TEST_END_DATE = '2022-06-01'\n",
    "\n",
    "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                     end_date = TEST_END_DATE,\n",
    "                     ticker_list = DOW_30_TICKER).fetch_data()\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(df.tail())\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "print(df.sort_values(['date','tic']).head())\n",
    "\n",
    "print(len(df.tic.unique()))\n",
    "\n",
    "print(df.tic.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block initializes the INDICATORS list with the names of four technical indicators: `macd`, `rsi_30`, `cci_30`, and `dx_30`.\n",
    "\n",
    "Next, an instance of the `FeatureEngineer` class is created with the following parameters:\n",
    "\n",
    "- `use_technical_indicator=True` to specify that technical indicators will be used in feature engineering.\n",
    "- `tech_indicator_list=INDICATORS` to specify the list of technical indicators to be used.\n",
    "- `use_turbulence=True` to specify that turbulence index will be used as a feature.\n",
    "- `user_defined_feature=False` to specify that no additional user-defined features will be used.\n",
    "\n",
    "The `preprocess_data` method of the `FeatureEngineer` instance is then called with the `df` parameter, which contains financial data in the form of a Pandas `DataFrame`. The resulting preprocessed data is then copied to a new `DataFrame` and missing values are filled with zeros using the `fillna(0)` method. Any infinite values are also replaced with zeros using the `replace(np.inf,0)` method.\n",
    "\n",
    "The `sample` method is then called on the processed `DataFrame` to display a random sample of five rows of the preprocessed data.\n",
    "\n",
    "The `stock_dimension` variable is then initialized to the number of unique stock tickers in the processed `DataFrame`, while `state_space` is initialized to a calculated value based on the number of stocks, technical indicators, and other features used. The `print` statement at the end of the script outputs the values of `stock_dimension` and `state_space`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDICATORS = ['macd',\n",
    "               'rsi_30',\n",
    "               'cci_30',\n",
    "               'dx_30']\n",
    "\n",
    "print(\"==============Preprocessing Data===========\")\n",
    "\n",
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_turbulence=True,\n",
    "                     user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)\n",
    "processed = processed.copy()\n",
    "processed = processed.fillna(0)\n",
    "processed = processed.replace(np.inf,0)\n",
    "\n",
    "print(processed.sample(5))\n",
    "\n",
    "stock_dimension = len(processed.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `env_kwargs` dictionary contains the configuration of the `StockTradingEnv`. Here are the definitions of the variables in the dictionary:\n",
    "\n",
    "- `hmax`: The maximum number of shares that can be traded per action.\n",
    "- `initial_amount`: The amount of cash with which the agent starts trading.\n",
    "- `buy_cost_pct`: The cost of buying stocks. This is a percentage of the total value of the stocks purchased.\n",
    "- `sell_cost_pct`: The cost of selling stocks. This is a percentage of the total value of the stocks sold.\n",
    "- `state_space`: The dimension of the state space of the environment. It is calculated as `1 + 2 * stock_dimension + len(INDICATORS) * stock_dimension`, where `stock_dimension` is the number of unique stock tickers in the dataset and `INDICATORS` is the list of technical indicators used to preprocess the data.\n",
    "- `stock_dim`: The number of unique stock tickers in the dataset.\n",
    "- `tech_indicator_list`: The list of technical indicators used to preprocess the data.\n",
    "- `action_space`: The dimension of the action space of the environment. It is equal to stock_dimension.\n",
    "- `reward_scaling`: A scaling factor used to normalize the reward.\n",
    "- `print_verbosity`: The level of verbosity of the environment.\n",
    "\n",
    "The `rebalance_window` and `validation_window` variables determine the duration of the rebalance and validation windows, respectively. The rebalance window is the number of days after which the model is retrained, while the validation window is the number of days used for validation and trading.\n",
    "\n",
    "The `DRLEnsembleAgent` object is used to train and evaluate the ensemble trading strategy. It takes in the preprocessed data, training and validation periods, rebalance and validation windows, and environment configuration as input arguments.\n",
    "\n",
    "The `A2C_model_kwargs`, `PPO_model_kwargs`, and `DDPG_model_kwargs` Dictionaries contain the hyperparameters for the A2C, PPO, and DDPG models, respectively. The hyperparameters include the learning rate, batch size, number of steps, entropy coefficient, and buffer size.\n",
    "\n",
    "The `timesteps_dict` dictionary contains the number of training steps for each model. The number of steps is set to 1 in this example.\n",
    "\n",
    "The `df_summary` `DataFrame` contains the summary statistics for the ensemble trading strategy. The statistics include the Sharpe ratio, annual return, maximum drawdown, and total number of trades.\n",
    "\n",
    "The `df_trade_date` `DataFrame` contains the unique trade dates for the trading period. The `df_account_value` `DataFrame` contains the account value for each trading day, as well as the portfolio value, daily return, and total return. These values are stored in separate CSV files for each rebalance period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 0.001, \n",
    "    \"sell_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}\n",
    "\n",
    "rebalance_window = 63 #63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 #63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed,\n",
    "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
    "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window, \n",
    "                 **env_kwargs)\n",
    "\n",
    "\n",
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.005,\n",
    "                    'learning_rate': 0.0007\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2, #2048\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 1, #10_000\n",
    "                      \"learning_rate\": 0.0005,\n",
    "                      \"batch_size\": 64\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 1, #10_000 each\n",
    "                 'ppo' : 1, \n",
    "                 'ddpg' : 1\n",
    "                 }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block performs an ensemble strategy run using an instance of the `DRLEnsembleAgent` class called `ensemble_agent`. This ensemble agent is trained to combine the predictions of multiple Deep Reinforcement Learning (DRL) models for better performance in stock trading.\n",
    "\n",
    "The `run_ensemble_strategy` method of the `DRLEnsembleAgent` instance is called with the following parameters:\n",
    "\n",
    "- `A2C_model_kwargs`, `PPO_model_kwargs`, and `DDPG_model_kwargs`: dictionaries containing keyword arguments that will be used to instantiate A2C, PPO, and DDPG models, respectively. These arguments can include hyperparameters such as learning rate, discount factor, number of hidden layers, etc.\n",
    "- `timesteps_dict`: a dictionary specifying the number of timesteps for training and testing each model. This can be useful for comparing performance of models with different training lengths.\n",
    "The `run_ensemble_strategy` method executes the ensemble strategy run and returns a summary of the results, which is stored in the `df_summary` DataFrame. This summary includes statistics such as total return, Sharpe ratio, maximum drawdown, and other performance metrics for the ensemble strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 PPO_model_kwargs,\n",
    "                                                 DDPG_model_kwargs,\n",
    "                                                 timesteps_dict)\n",
    "\n",
    "df_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block performs an analysis of the performance of the trading strategy over a test period. The first step is to identify the unique trading dates within the test period using the `unique_trade_date` variable. This is achieved by filtering the processed DataFrame to include only dates that are greater than `TEST_START_DATE` and less than or equal to `TEST_END_DATE`, and then selecting only the unique dates using the `unique()` method.\n",
    "\n",
    "The `df_trade_date` DataFrame is then created to store these unique trading dates in a column named `datadate`. An empty DataFrame called `df_account_value` is also initialized to store the account value data from each rebalancing period.\n",
    "\n",
    "A loop is then executed to read the account value data from the rebalancing periods and concatenate it into `df_account_value`. The loop iterates over each rebalancing period, which has a length of `rebalance_window + validation_window`. The `pd.read_csv()` function reads the CSV file that contains the account value data for the corresponding rebalancing period and saves it to a temporary DataFrame called `temp`. The `df_account_value` DataFrame is then concatenated with `temp` using the `pd.concat()` function to append the data from the current rebalancing period to the overall DataFrame. The `ignore_index=True` parameter ensures that the indices of the original DataFrames are not used in the concatenated DataFrame.\n",
    "\n",
    "Finally, the Sharpe ratio of the trading strategy is calculated using the formula `sharpe = (252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()`. The Sharpe ratio is a measure of risk-adjusted return that is commonly used to evaluate investment strategies. It is calculated as the ratio of the average excess return earned over the risk-free rate per unit of volatility or standard deviation of returns. In this case, the daily returns of the trading strategy are used to calculate the Sharpe ratio. The Sharpe ratio is printed to the console using the `print()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()\n",
    "\n",
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "df_account_value = pd.DataFrame()\n",
    "\n",
    "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = pd.concat([df_account_value, temp], ignore_index=True)\n",
    "\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "\n",
    "print('Sharpe Ratio: ',sharpe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code block aims to plot the account value over time for the rebalancing periods in the `df_account_value` DataFrame. To achieve this, `df_account_value` is joined with `df_trade_date` on the datadate column. The `validation_window` number of rows from the beginning of `df_trade_date` are skipped using the `df_trade_date[validation_window:]` slicing syntax. The `reset_index()` method is called on the sliced DataFrame to reset the index to start from zero, and the `drop=True` parameter is used to drop the original index column.\n",
    "\n",
    "The resulting DataFrame is stored back in `df_account_value`. This ensures that both DataFrames have the same number of rows, which is required for plotting.\n",
    "\n",
    "Next, the `head()` method is called on `df_account_value` to display the first few rows of the DataFrame. This provides an overview of the data, including the account value and the corresponding dates for each rebalancing period.\n",
    "\n",
    "Finally, the `account_value` column of `df_account_value` is selected and plotted using the `plot()` method. This generates a line plot of the account value over time, with the x-axis representing the dates and the y-axis representing the account value. The plot provides a visual representation of the performance of the trading strategy over the rebalancing periods. It can be used to identify trends, patterns, and anomalies in the account value data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\n",
    "\n",
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_account_value.account_value.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "              baseline_ticker = '^DJI', \n",
    "              baseline_start = df_account_value.loc[0,'date'],\n",
    "              baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
